{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8193883f",
   "metadata": {},
   "source": [
    "# Generalized Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13e4a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, unix_timestamp\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0598ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"YellowTaxiTripPrediction\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b05efc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:>                                                       (0 + 20) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day_of_week: integer (nullable = true)\n",
      " |-- trip_duration_seconds: double (nullable = true)\n",
      " |-- speed_mph: double (nullable = true)\n",
      " |-- extras: double (nullable = true)\n",
      " |-- PU_Borough: string (nullable = true)\n",
      " |-- PU_Zone: string (nullable = true)\n",
      " |-- DO_Borough: string (nullable = true)\n",
      " |-- DO_Zone: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"../data/full_tripdata.parquet\", header=False, inferSchema=True)\n",
    "\n",
    "column_names = [\n",
    "    \"PULocationID\", \"DOLocationID\", \"passenger_count\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\",\n",
    "    \"VendorID\", \"trip_distance\", \"payment_type\", \"fare_amount\", \"tip_amount\", \"total_amount\",\n",
    "    \"hour\", \"day_of_week\", \"trip_duration_seconds\", \"speed_mph\", \"extras\",\n",
    "    \"PU_Borough\", \"PU_Zone\", \"DO_Borough\", \"DO_Zone\"\n",
    "]\n",
    "df = df.toDF(*column_names)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "440898f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+---------------+--------------------+---------------------+--------+-------------+------------+-----------+----------+------------+----+-----------+---------------------+------------------+------------------+----------+--------------------+----------+--------------------+\n",
      "|PULocationID|DOLocationID|passenger_count|tpep_pickup_datetime|tpep_dropoff_datetime|VendorID|trip_distance|payment_type|fare_amount|tip_amount|total_amount|hour|day_of_week|trip_duration_seconds|         speed_mph|            extras|PU_Borough|             PU_Zone|DO_Borough|             DO_Zone|\n",
      "+------------+------------+---------------+--------------------+---------------------+--------+-------------+------------+-----------+----------+------------+----+-----------+---------------------+------------------+------------------+----------+--------------------+----------+--------------------+\n",
      "|         236|          68|              2| 2024-02-01 00:04:45|  2024-02-01 00:19:58|       1|         4.39|           1|       20.5|      1.28|       26.78|   0|          5|                913.0| 17.30996714129244|               5.0| Manhattan|        East Chelsea| Manhattan|Upper East Side N...|\n",
      "|         243|          48|              2| 2024-02-01 00:56:31|  2024-02-01 01:10:53|       1|         7.71|           1|       31.0|       9.0|        45.0|   0|          5|                862.0| 32.19953596287703|               5.0| Manhattan|        Clinton East| Manhattan|Washington Height...|\n",
      "|         261|         132|              2| 2024-02-01 00:07:50|  2024-02-01 00:43:12|       2|        28.69|           2|       70.0|       0.0|       82.69|   0|          5|               2122.0|48.672950047125354|12.690000000000001|    Queens|         JFK Airport| Manhattan|  World Trade Center|\n",
      "|         163|         161|              1| 2024-02-01 00:01:49|  2024-02-01 00:10:47|       1|          1.1|           1|        9.3|      2.85|       17.15|   0|          5|                538.0|7.3605947955390345|               7.5| Manhattan|      Midtown Center| Manhattan|       Midtown North|\n",
      "|          79|         246|              1| 2024-02-01 00:37:35|  2024-02-01 00:51:15|       1|          2.6|           2|       15.6|       0.0|        20.6|   0|          5|                820.0|11.414634146341465|               7.5| Manhattan|West Chelsea/Huds...| Manhattan|        East Village|\n",
      "+------------+------------+---------------+--------------------+---------------------+--------+-------------+------------+-----------+----------+------------+----+-----------+---------------------+------------------+------------------+----------+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9b95f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant columns\n",
    "selected_cols = [\"trip_distance\", \"passenger_count\", \"PULocationID\", \"DOLocationID\", \n",
    "                 \"VendorID\", \"total_amount\", \"payment_type\",\"hour\", \"day_of_week\",\n",
    "                 \"trip_duration_seconds\", \"speed_mph\", \"extras\"]\n",
    "df_model = df.select(*selected_cols)\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"trip_distance\", \"passenger_count\", \"PULocationID\", \"DOLocationID\", \n",
    "                 \"VendorID\", \"payment_type\",\"hour\", \"day_of_week\", \"trip_duration_seconds\",\n",
    "                 \"speed_mph\", \"extras\"],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5d0f619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "train_data, test_data = df_model.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "670b1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning data\n",
    "train_data = train_data.na.drop(subset=[\n",
    "    \"trip_distance\", \"passenger_count\", \"PULocationID\", \"DOLocationID\", \"VendorID\",\n",
    "    \"payment_type\", \"hour\", \"day_of_week\",\n",
    "    \"trip_duration_seconds\", \"speed_mph\", \"extras\", \"total_amount\"\n",
    "])\n",
    "\n",
    "test_data = test_data.na.drop(subset=[\n",
    "    \"trip_distance\", \"passenger_count\", \"PULocationID\", \"DOLocationID\", \"VendorID\",\n",
    "    \"payment_type\", \"hour\", \"day_of_week\",\n",
    "    \"trip_duration_seconds\", \"speed_mph\", \"extras\", \"total_amount\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e931284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Model creation and training\n",
    "glr = GeneralizedLinearRegression(\n",
    "    labelCol=\"total_amount\", \n",
    "    featuresCol=\"features\", \n",
    "    maxIter=10, \n",
    "    regParam=0.1,\n",
    "    family=\"gaussian\", \n",
    "    link=\"identity\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, glr])\n",
    "model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de8397b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:======================>                                 (8 + 12) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 16.20\n",
      "MAE: 9.71\n",
      "RÂ²: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluators and metrics\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"total_amount\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"total_amount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"total_amount\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RÂ²: {r2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
